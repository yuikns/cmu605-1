Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
15/11/12 00:08:08 INFO SparkContext: Running Spark version 1.5.1
15/11/12 00:08:08 INFO SecurityManager: Changing view acls to: jingyual
15/11/12 00:08:08 INFO SecurityManager: Changing modify acls to: jingyual
15/11/12 00:08:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jingyual); users with modify permissions: Set(jingyual)
15/11/12 00:08:09 INFO Slf4jLogger: Slf4jLogger started
15/11/12 00:08:09 INFO Remoting: Starting remoting
15/11/12 00:08:10 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@128.2.13.134:49433]
15/11/12 00:08:10 INFO Utils: Successfully started service 'sparkDriver' on port 49433.
15/11/12 00:08:10 INFO SparkEnv: Registering MapOutputTracker
15/11/12 00:08:10 INFO SparkEnv: Registering BlockManagerMaster
15/11/12 00:08:10 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-46842e2b-183f-4bbb-a1f4-6c3fcb72ed65
15/11/12 00:08:10 INFO MemoryStore: MemoryStore started with capacity 1060.3 MB
15/11/12 00:08:10 INFO HttpFileServer: HTTP File server directory is /tmp/spark-efa32664-3194-4923-adb0-f8848fea3ef7/httpd-08dbc819-e137-4c10-9fe1-69dbf909a109
15/11/12 00:08:10 INFO HttpServer: Starting HTTP Server
15/11/12 00:08:10 INFO Utils: Successfully started service 'HTTP file server' on port 33746.
15/11/12 00:08:10 INFO SparkEnv: Registering OutputCommitCoordinator
15/11/12 00:08:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
15/11/12 00:08:10 INFO Utils: Successfully started service 'SparkUI' on port 4041.
15/11/12 00:08:10 INFO SparkUI: Started SparkUI at http://128.2.13.134:4041
15/11/12 00:08:10 INFO Utils: Copying /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py to /tmp/spark-efa32664-3194-4923-adb0-f8848fea3ef7/userFiles-86a987d2-9553-4377-94d7-caa4a07b81e4/dsgd_mf.py
15/11/12 00:08:10 INFO SparkContext: Added file file:/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py at file:/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py with timestamp 1447304890517
15/11/12 00:08:10 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
15/11/12 00:08:10 INFO Executor: Starting executor ID driver on host localhost
15/11/12 00:08:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34535.
15/11/12 00:08:10 INFO NettyBlockTransferService: Server created on 34535
15/11/12 00:08:10 INFO BlockManagerMaster: Trying to register BlockManager
15/11/12 00:08:10 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34535 with 1060.3 MB RAM, BlockManagerId(driver, localhost, 34535)
15/11/12 00:08:10 INFO BlockManagerMaster: Registered BlockManager
15/11/12 00:08:11 INFO MemoryStore: ensureFreeSpace(45712) called with curMem=0, maxMem=1111794647
15/11/12 00:08:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 44.6 KB, free 1060.2 MB)
15/11/12 00:08:11 INFO MemoryStore: ensureFreeSpace(4251) called with curMem=45712, maxMem=1111794647
15/11/12 00:08:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 1060.2 MB)
15/11/12 00:08:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34535 (size: 4.2 KB, free: 1060.3 MB)
15/11/12 00:08:11 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
15/11/12 00:08:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/11/12 00:08:11 WARN LoadSnappy: Snappy native library not loaded
15/11/12 00:08:11 INFO FileInputFormat: Total input paths to process : 1
15/11/12 00:08:11 INFO SparkContext: Starting job: reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:166
15/11/12 00:08:11 INFO DAGScheduler: Got job 0 (reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:166) with 2 output partitions
15/11/12 00:08:11 INFO DAGScheduler: Final stage: ResultStage 0(reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:166)
15/11/12 00:08:11 INFO DAGScheduler: Parents of final stage: List()
15/11/12 00:08:11 INFO DAGScheduler: Missing parents: List()
15/11/12 00:08:11 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:166), which has no missing parents
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(6144) called with curMem=49963, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.0 KB, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(3835) called with curMem=56107, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34535 (size: 3.7 KB, free: 1060.3 MB)
15/11/12 00:08:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:861
15/11/12 00:08:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (PythonRDD[2] at reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:166)
15/11/12 00:08:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
15/11/12 00:08:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2263 bytes)
15/11/12 00:08:12 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2263 bytes)
15/11/12 00:08:12 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
15/11/12 00:08:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
15/11/12 00:08:12 INFO Executor: Fetching file:/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py with timestamp 1447304890517
15/11/12 00:08:12 INFO Utils: /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py has been previously copied to /tmp/spark-efa32664-3194-4923-adb0-f8848fea3ef7/userFiles-86a987d2-9553-4377-94d7-caa4a07b81e4/dsgd_mf.py
15/11/12 00:08:12 INFO HadoopRDD: Input split: file:/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/data/transfer.csv:0+2978
15/11/12 00:08:12 INFO HadoopRDD: Input split: file:/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/data/transfer.csv:2978+2978
15/11/12 00:08:12 INFO PythonRunner: Times: total = 286, boot = 274, init = 11, finish = 1
15/11/12 00:08:12 INFO PythonRunner: Times: total = 287, boot = 271, init = 14, finish = 2
15/11/12 00:08:12 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2124 bytes result sent to driver
15/11/12 00:08:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2124 bytes result sent to driver
15/11/12 00:08:12 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 422 ms on localhost (1/2)
15/11/12 00:08:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 451 ms on localhost (2/2)
15/11/12 00:08:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
15/11/12 00:08:12 INFO DAGScheduler: ResultStage 0 (reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:166) finished in 0.474 s
15/11/12 00:08:12 INFO DAGScheduler: Job 0 finished: reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:166, took 0.570500 s
15/11/12 00:08:12 INFO SparkContext: Starting job: reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:168
15/11/12 00:08:12 INFO DAGScheduler: Got job 1 (reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:168) with 2 output partitions
15/11/12 00:08:12 INFO DAGScheduler: Final stage: ResultStage 1(reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:168)
15/11/12 00:08:12 INFO DAGScheduler: Parents of final stage: List()
15/11/12 00:08:12 INFO DAGScheduler: Missing parents: List()
15/11/12 00:08:12 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[3] at reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:168), which has no missing parents
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(6144) called with curMem=59942, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.0 KB, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(3835) called with curMem=66086, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34535 (size: 3.7 KB, free: 1060.3 MB)
15/11/12 00:08:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
15/11/12 00:08:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[3] at reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:168)
15/11/12 00:08:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
15/11/12 00:08:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2263 bytes)
15/11/12 00:08:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2263 bytes)
15/11/12 00:08:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
15/11/12 00:08:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
15/11/12 00:08:12 INFO HadoopRDD: Input split: file:/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/data/transfer.csv:2978+2978
15/11/12 00:08:12 INFO HadoopRDD: Input split: file:/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/data/transfer.csv:0+2978
15/11/12 00:08:12 INFO PythonRunner: Times: total = 42, boot = -100, init = 141, finish = 1
15/11/12 00:08:12 INFO PythonRunner: Times: total = 42, boot = -103, init = 144, finish = 1
15/11/12 00:08:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 2124 bytes result sent to driver
15/11/12 00:08:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 2124 bytes result sent to driver
15/11/12 00:08:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 63 ms on localhost (1/2)
15/11/12 00:08:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 67 ms on localhost (2/2)
15/11/12 00:08:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
15/11/12 00:08:12 INFO DAGScheduler: ResultStage 1 (reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:168) finished in 0.067 s
15/11/12 00:08:12 INFO DAGScheduler: Job 1 finished: reduce at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:168, took 0.081469 s
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(288) called with curMem=69921, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 288.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(92) called with curMem=70209, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 92.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:34535 (size: 92.0 B, free: 1060.3 MB)
15/11/12 00:08:12 INFO SparkContext: Created broadcast 3 from broadcast at PythonRDD.scala:430
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(288) called with curMem=70301, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 288.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(92) called with curMem=70589, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 92.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:34535 (size: 92.0 B, free: 1060.3 MB)
15/11/12 00:08:12 INFO SparkContext: Created broadcast 4 from broadcast at PythonRDD.scala:430
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(288) called with curMem=70681, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 288.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(99) called with curMem=70969, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 99.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:34535 (size: 99.0 B, free: 1060.3 MB)
15/11/12 00:08:12 INFO SparkContext: Created broadcast 5 from broadcast at PythonRDD.scala:430
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(288) called with curMem=71068, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 288.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(1018) called with curMem=71356, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1018.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:34535 (size: 1018.0 B, free: 1060.3 MB)
15/11/12 00:08:12 INFO SparkContext: Created broadcast 6 from broadcast at PythonRDD.scala:430
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(288) called with curMem=72374, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 288.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(1018) called with curMem=72662, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1018.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:34535 (size: 1018.0 B, free: 1060.3 MB)
15/11/12 00:08:12 INFO SparkContext: Created broadcast 7 from broadcast at PythonRDD.scala:430
15/11/12 00:08:12 INFO SparkContext: Starting job: collect at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:221
15/11/12 00:08:12 INFO DAGScheduler: Registering RDD 5 (partitionBy at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:202)
15/11/12 00:08:12 INFO DAGScheduler: Got job 2 (collect at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:221) with 5 output partitions
15/11/12 00:08:12 INFO DAGScheduler: Final stage: ResultStage 3(collect at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:221)
15/11/12 00:08:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
15/11/12 00:08:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
15/11/12 00:08:12 INFO DAGScheduler: Submitting ShuffleMapStage 2 (PairwiseRDD[5] at partitionBy at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:202), which has no missing parents
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(8008) called with curMem=73680, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 7.8 KB, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(5092) called with curMem=81688, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.0 KB, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:34535 (size: 5.0 KB, free: 1060.3 MB)
15/11/12 00:08:12 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:861
15/11/12 00:08:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (PairwiseRDD[5] at partitionBy at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:202)
15/11/12 00:08:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
15/11/12 00:08:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2252 bytes)
15/11/12 00:08:12 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2252 bytes)
15/11/12 00:08:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
15/11/12 00:08:12 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
15/11/12 00:08:12 INFO HadoopRDD: Input split: file:/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/data/transfer.csv:2978+2978
15/11/12 00:08:12 INFO HadoopRDD: Input split: file:/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/data/transfer.csv:0+2978
15/11/12 00:08:12 INFO PythonRunner: Times: total = 43, boot = -188, init = 229, finish = 2
15/11/12 00:08:12 INFO PythonRunner: Times: total = 44, boot = -188, init = 230, finish = 2
15/11/12 00:08:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 2321 bytes result sent to driver
15/11/12 00:08:12 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 2321 bytes result sent to driver
15/11/12 00:08:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 90 ms on localhost (1/2)
15/11/12 00:08:12 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 89 ms on localhost (2/2)
15/11/12 00:08:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
15/11/12 00:08:12 INFO DAGScheduler: ShuffleMapStage 2 (partitionBy at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:202) finished in 0.093 s
15/11/12 00:08:12 INFO DAGScheduler: looking for newly runnable stages
15/11/12 00:08:12 INFO DAGScheduler: running: Set()
15/11/12 00:08:12 INFO DAGScheduler: waiting: Set(ResultStage 3)
15/11/12 00:08:12 INFO DAGScheduler: failed: Set()
15/11/12 00:08:12 INFO DAGScheduler: Missing parents for ResultStage 3: List()
15/11/12 00:08:12 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[9] at collect at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:221), which is now runnable
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(8632) called with curMem=86780, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 8.4 KB, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(5257) called with curMem=95412, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.1 KB, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:34535 (size: 5.1 KB, free: 1060.3 MB)
15/11/12 00:08:12 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:861
15/11/12 00:08:12 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (PythonRDD[9] at collect at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:221)
15/11/12 00:08:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
15/11/12 00:08:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, PROCESS_LOCAL, 1979 bytes)
15/11/12 00:08:12 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, PROCESS_LOCAL, 1979 bytes)
15/11/12 00:08:12 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, PROCESS_LOCAL, 1979 bytes)
15/11/12 00:08:12 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, PROCESS_LOCAL, 1979 bytes)
15/11/12 00:08:12 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 10, localhost, PROCESS_LOCAL, 1979 bytes)
15/11/12 00:08:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
15/11/12 00:08:12 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
15/11/12 00:08:12 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
15/11/12 00:08:12 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
15/11/12 00:08:12 INFO Executor: Running task 4.0 in stage 3.0 (TID 10)
15/11/12 00:08:12 INFO CacheManager: Partition rdd_8_0 not found, computing it
15/11/12 00:08:12 INFO CacheManager: Partition rdd_8_4 not found, computing it
15/11/12 00:08:12 INFO CacheManager: Partition rdd_8_1 not found, computing it
15/11/12 00:08:12 INFO CacheManager: Partition rdd_8_3 not found, computing it
15/11/12 00:08:12 INFO CacheManager: Partition rdd_8_2 not found, computing it
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
15/11/12 00:08:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
15/11/12 00:08:12 INFO PythonRunner: Times: total = 8, boot = 3, init = 4, finish = 1
15/11/12 00:08:12 INFO PythonRunner: Times: total = 9, boot = 5, init = 4, finish = 0
15/11/12 00:08:12 INFO PythonRunner: Times: total = 11, boot = 6, init = 4, finish = 1
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(656) called with curMem=100669, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block rdd_8_0 stored as bytes in memory (estimated size 656.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(795) called with curMem=101325, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block rdd_8_2 stored as bytes in memory (estimated size 795.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added rdd_8_0 in memory on localhost:34535 (size: 656.0 B, free: 1060.3 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(1015) called with curMem=102120, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block rdd_8_3 stored as bytes in memory (estimated size 1015.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added rdd_8_2 in memory on localhost:34535 (size: 795.0 B, free: 1060.3 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added rdd_8_3 in memory on localhost:34535 (size: 1015.0 B, free: 1060.3 MB)
15/11/12 00:08:12 INFO PythonRunner: Times: total = 42, boot = -85, init = 127, finish = 0
15/11/12 00:08:12 INFO PythonRunner: Times: total = 43, boot = -83, init = 126, finish = 0
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(926) called with curMem=103135, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block rdd_8_4 stored as bytes in memory (estimated size 926.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO MemoryStore: ensureFreeSpace(657) called with curMem=104061, maxMem=1111794647
15/11/12 00:08:12 INFO MemoryStore: Block rdd_8_1 stored as bytes in memory (estimated size 657.0 B, free 1060.2 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added rdd_8_4 in memory on localhost:34535 (size: 926.0 B, free: 1060.3 MB)
15/11/12 00:08:12 INFO BlockManagerInfo: Added rdd_8_1 in memory on localhost:34535 (size: 657.0 B, free: 1060.3 MB)
15/11/12 00:08:13 INFO PythonRunner: Times: total = 44, boot = 3, init = 41, finish = 0
15/11/12 00:08:13 INFO PythonRunner: Times: total = 44, boot = 4, init = 40, finish = 0
15/11/12 00:08:13 ERROR Executor: Exception in task 0.0 in stage 3.0 (TID 6)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/afs/cs.cmu.edu/project/bigML/spark/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/afs/cs.cmu.edu/project/bigML/spark/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/afs/cs.cmu.edu/project/bigML/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py", line 117, in perform_sgd
    w_mat_block_part = np.copy(w_mat_block[word_id - row_start])
IndexError: index 12 is out of bounds for axis 0 with size 4

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/11/12 00:08:13 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 1793 bytes result sent to driver
15/11/12 00:08:13 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 1793 bytes result sent to driver
15/11/12 00:08:13 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 103 ms on localhost (1/5)
15/11/12 00:08:13 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 102 ms on localhost (2/5)
15/11/12 00:08:13 WARN TaskSetManager: Lost task 0.0 in stage 3.0 (TID 6, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/afs/cs.cmu.edu/project/bigML/spark/python/lib/pyspark.zip/pyspark/worker.py", line 111, in main
    process()
  File "/afs/cs.cmu.edu/project/bigML/spark/python/lib/pyspark.zip/pyspark/worker.py", line 106, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/afs/cs.cmu.edu/project/bigML/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py", line 117, in perform_sgd
    w_mat_block_part = np.copy(w_mat_block[word_id - row_start])
IndexError: index 12 is out of bounds for axis 0 with size 4

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)

15/11/12 00:08:13 ERROR TaskSetManager: Task 0 in stage 3.0 failed 1 times; aborting job
15/11/12 00:08:13 INFO TaskSchedulerImpl: Cancelling stage 3
15/11/12 00:08:13 INFO PythonRunner: Times: total = 42, boot = 2, init = 40, finish = 0
15/11/12 00:08:13 INFO PythonRunner: Times: total = 42, boot = 1, init = 41, finish = 0
15/11/12 00:08:13 INFO Executor: Finished task 4.0 in stage 3.0 (TID 10). 1793 bytes result sent to driver
15/11/12 00:08:13 INFO TaskSchedulerImpl: Stage 3 was cancelled
15/11/12 00:08:13 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 1793 bytes result sent to driver
15/11/12 00:08:13 INFO DAGScheduler: ResultStage 3 (collect at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:221) failed in 0.130 s
15/11/12 00:08:13 INFO DAGScheduler: Job 2 failed: collect at /afs/andrew.cmu.edu/usr7/jingyual/public/cmu605/dsgd/dsgd_mf.py:221, took 0.274538 s
15/11/12 00:08:13 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 131 ms on localhost (3/5)
15/11/12 00:08:13 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/11/12 00:08:13 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 10) in 129 ms on localhost (4/5)
15/11/12 00:08:13 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
15/11/12 00:08:13 INFO SparkContext: Invoking stop() from shutdown hook
15/11/12 00:08:13 INFO SparkUI: Stopped Spark web UI at http://128.2.13.134:4041
15/11/12 00:08:13 INFO DAGScheduler: Stopping DAGScheduler
15/11/12 00:08:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
15/11/12 00:08:13 INFO MemoryStore: MemoryStore cleared
15/11/12 00:08:13 INFO BlockManager: BlockManager stopped
15/11/12 00:08:13 INFO BlockManagerMaster: BlockManagerMaster stopped
15/11/12 00:08:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
15/11/12 00:08:13 INFO SparkContext: Successfully stopped SparkContext
15/11/12 00:08:13 INFO ShutdownHookManager: Shutdown hook called
15/11/12 00:08:13 INFO ShutdownHookManager: Deleting directory /tmp/spark-efa32664-3194-4923-adb0-f8848fea3ef7
